{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import pyttsx3\n",
    "from TTS.api import TTS\n",
    "\n",
    "from IPython.display import Audio, clear_output\n",
    "\n",
    "from so_vits_svc_fork.inference.core import Svc\n",
    "from so_vits_svc_fork.utils import get_optimal_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech_old(text, sr_target):\n",
    "    engine = pyttsx3.init()  # Initialize the text-to-speech engine\n",
    "\n",
    "    # Set the properties for the engine\n",
    "    engine.setProperty('rate', 125)     # words spoken per minute\n",
    "    engine.setProperty('volume', 1.0)   # volume level between 0 and 1\n",
    "\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[0].id)  # set the voice to female\n",
    "\n",
    "    # Use pyttsx3 to generate audio and save it\n",
    "    engine.save_to_file(text, 'audio.wav')\n",
    "    engine.runAndWait()\n",
    "\n",
    "    # Load audio from the byte array using soundfile\n",
    "    audio, _ = librosa.load('audio.wav', sr=sr_target)\n",
    "\n",
    "    return audio\n",
    "\n",
    "def text_to_speech(text, sr_target):\n",
    "    # List available ðŸ¸TTS models and choose the first one\n",
    "    # print(TTS.list_models())\n",
    "    model_name = TTS.list_models()[0]\n",
    "    # model_name = 'tts_models/en/ljspeech/glow-tts'\n",
    "    # Init TTS\n",
    "    tts = TTS(model_name, progress_bar=True, gpu=True)\n",
    "    # Text to speech to a file\n",
    "    print(tts.speakers)\n",
    "    print(tts.languages)\n",
    "    tts.tts_to_file(text=text, speaker=tts.speakers[3], language=tts.languages[0], file_path=\"audio.wav\", emotion=\"Angry\")\n",
    "    #multi speaker model requires these speaker=tts.speakers[0], language=tts.languages[0],\n",
    "    #emotions\n",
    "    #Neutral Dull Happy Sad Surprise Angry\n",
    "\n",
    "\n",
    "    # Load audio from the byte array using soundfile\n",
    "    audio, _ = librosa.load('audio.wav', sr=sr_target)\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "\n",
    "audio = text_to_speech(\"testing text to speech\", 44100)\n",
    "Audio(data=audio, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "config_path = \"\"\n",
    "cluster_model_path = \"\"\n",
    "device: str | torch.device = get_optimal_device()\n",
    "\n",
    "svc_model = Svc(\n",
    "        net_g_path=model_path,\n",
    "        config_path=config_path,\n",
    "        cluster_model_path=cluster_model_path\n",
    "        if cluster_model_path\n",
    "        else None,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "print(\"Warming up the model...\")\n",
    "svc_model.infer(\n",
    "    speaker=0,\n",
    "    transpose=0,\n",
    "    auto_predict_f0=False,\n",
    "    cluster_infer_ratio=0,\n",
    "    noise_scale=0.4,\n",
    "    f0_method=\"dio\", #\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"\n",
    "    audio=np.zeros(svc_model.target_sample, dtype=np.float32),\n",
    ")\n",
    "\n",
    "# audio, _ = librosa.load(\"\", sr=svc_model.target_sample)\n",
    "\n",
    "# audio = svc_model.infer_silence(\n",
    "#                 audio.astype(np.float32),\n",
    "#                 speaker=0,\n",
    "#                 transpose=0,\n",
    "#                 auto_predict_f0=True,\n",
    "#                 cluster_infer_ratio=0,\n",
    "#                 noise_scale=0.4,\n",
    "#                 f0_method=\"dio\", #\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"\n",
    "#                 db_thresh=-40,\n",
    "#                 pad_seconds=0.5,\n",
    "#                 chunk_seconds=0.5,\n",
    "#                 absolute_thresh=False,\n",
    "#                 max_chunk_seconds=40,\n",
    "#             )\n",
    "\n",
    "# Clear the output\n",
    "clear_output(wait=False)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = text_to_speech(\"\\\n",
    "                        ðŸ¸TTS is tested on Ubuntu 18.04 with python >= 3.7, < 3.11..\\\n",
    "If you are only interested in synthesizing speech with the released ðŸ¸TTS models, installing from PyPI is the easiest option.\\\n",
    "                       \", svc_model.target_sample)\n",
    "\n",
    "\n",
    "audio = svc_model.infer_silence(\n",
    "                audio.astype(np.float32),\n",
    "                speaker=0,\n",
    "                transpose=0,\n",
    "                auto_predict_f0=True,\n",
    "                cluster_infer_ratio=0,\n",
    "                noise_scale=0.1,\n",
    "                f0_method=\"dio\", #\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"\n",
    "                db_thresh=-100,\n",
    "                pad_seconds=1,\n",
    "                chunk_seconds=0.5,\n",
    "                absolute_thresh=False,\n",
    "                max_chunk_seconds=40,\n",
    "            )\n",
    "\n",
    "# Clear the output\n",
    "clear_output(wait=True)\n",
    "Audio(data=audio, rate=svc_model.target_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-so-vits-svc-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
